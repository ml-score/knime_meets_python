{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ebb351",
   "metadata": {},
   "source": [
    "### Use Python LightGBM and Optuna hyper parameter tuning to build model and deploy with KNIME Python nodes\n",
    "\n",
    "\n",
    "<img src=\"../KNIME_loves_lightgbm_optuna.png\" width=\"600\">\n",
    "\n",
    "\n",
    "##### KNIME workflows for Binary Classifications\n",
    "https://hub.knime.com/-/spaces/-/~GABT_OgeoWxWJW9P/current-state/\n",
    "\n",
    "https://hub.knime.com/-/spaces/-/~0dXvsD0vMrv_w6Fw/current-state/\n",
    "\n",
    "\n",
    "##### MEDIUM Blog: Hyperparameter optimization for LightGBM — wrapped in KNIME nodes\n",
    "\n",
    "https://medium.com/p/ddb7ae1d7e2\n",
    "\n",
    "###### Optuna\n",
    "\n",
    "https://optuna.readthedocs.io/en/stable/index.html\n",
    "\n",
    "###### additional links and texts\n",
    "\n",
    "https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html#for-better-accuracy\n",
    "\n",
    "https://stackoverflow.com/questions/67080149/xgboost-error-when-categorical-type-is-supplied-dmatrix-parameter-enable-cat\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/how-to-beat-the-heck-out-of-xgboost-with-lightgbm-comprehensive-tutorial-5eba52195997\n",
    "\n",
    "https://towardsdatascience.com/kagglers-guide-to-lightgbm-hyperparameter-tuning-with-optuna-in-2021-ed048d9838b5\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f\n",
    "\n",
    "some parameters have been discussed with ChatGPT ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e8bd4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import json\n",
    "import pickle\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f095555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation, record_evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, auc, average_precision_score, precision_recall_curve\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import matplotlib\n",
    "import kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fd127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://strftime.org'\n",
    "import time\n",
    "var_timestamp_day = \"{}\".format(time.strftime(\"%Y%m%d\"))\n",
    "# flow_variables['var_timestamp_day'] = var_timestamp_day\n",
    "print(\"var_timestamp_day: \", var_timestamp_day)\n",
    "\n",
    "var_timestamp_time = \"{}h\".format(time.strftime(\"%H%M\"))\n",
    "# flow_variables['var_timestamp_time'] = var_timestamp_time\n",
    "print(\"var_timestamp_time: \", var_timestamp_time)\n",
    "\n",
    "# _edit: if you want to have another model name\n",
    "var_model_name = \"LightGBM_Optuna_Classification\"\n",
    "# flow_variables['var_model_name'] = var_model_name\n",
    "\n",
    "var_model_name_full = var_model_name + \"_\" + var_timestamp_day  + \"_\" + var_timestamp_time + \"_jupyter\"\n",
    "# flow_variables['var_model_name_full'] = var_model_name_full\n",
    "print(\"var_model_name_full: \", var_model_name_full)\n",
    "\n",
    "# if you dp not want to store the files in the working directory\n",
    "var_path_data = \"../result/\"\n",
    "var_path_model = \"../model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a6c436",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data      = pq.read_table(\"../train.parquet\").to_pandas()\n",
    "data_test = pq.read_table(\"../test.parquet\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d085dd1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff52bbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_test = data_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f623d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "excluded_features = ['row_id']\n",
    "label = ['Target']\n",
    "# features = [feat for feat in data.columns if feat not in excluded_features and not feat==label]\n",
    "features = [feat for feat in data.columns if feat not in excluded_features and feat not in label]\n",
    "\n",
    "num_cols = data[features].select_dtypes(include='number').columns.tolist()\n",
    "cat_cols = data[features].select_dtypes(exclude='number').columns.tolist()\n",
    "\n",
    "rest_cols = [feat for feat in data.columns if feat not in cat_cols]\n",
    "\n",
    "print(f'''{\"data shape:\":20} {data.shape}\n",
    "{\"data[features] shape:\":20} {data[features].shape}\n",
    "categorical columns: {cat_cols}\n",
    "numerical columns: {num_cols}\n",
    "feature columns: {features}\n",
    "rest columns: {rest_cols}''')\n",
    "\n",
    "# THX David Gutmann "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7606646",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b8630c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[cat_cols] = data[cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e7647c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[label] = data[label].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a07e60",
   "metadata": {},
   "source": [
    "### Normalize by Log(), Decimal or Robust Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada9d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of decimal places for the scaling\n",
    "decimal_places_n = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd0468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decimal_scaling(input_df, cols_to_normalize, decimal_places):\n",
    "    \"\"\"\n",
    "    Apply decimal scaling to the selected columns in the input dataframe and return a new dataframe with the scaled values.\n",
    "    \n",
    "    Parameters:\n",
    "    input_df (pandas.DataFrame): The input dataframe to be scaled.\n",
    "    cols_to_normalize (list): A list of column names to be scaled.\n",
    "    decimal_places (int): The number of decimal places to scale the values.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: A new dataframe with the scaled values.\n",
    "    \"\"\"\n",
    "    output_df = input_df.copy()\n",
    "    for col in cols_to_normalize:\n",
    "        max_value = input_df[col].max()\n",
    "        min_value = input_df[col][input_df[col] > 0].min()\n",
    "        scaling_factor = 10 ** (len(str(int(max_value))) - decimal_places)\n",
    "        output_df[col] = input_df[col].apply(lambda x: (x - min_value) / scaling_factor)\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply decimal scaling to the input dataframe and store the result in the output dataframe\n",
    "data_normalized = decimal_scaling(input_df=data, cols_to_normalize=num_cols, decimal_places=decimal_places_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6369e007",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d7163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def log_scaling(input_df, cols_to_transform, cols_to_normalize, decimal_places=2):\n",
    "    \"\"\"\n",
    "    Apply log transformation and Min-Max scaling to the selected columns in the input dataframe and return a new dataframe with the transformed and normalized values.\n",
    "    \n",
    "    Parameters:\n",
    "    input_df (pandas.DataFrame): The input dataframe to be transformed and scaled.\n",
    "    cols_to_transform (list): A list of column names to be transformed with log.\n",
    "    cols_to_normalize (list): A list of column names to be normalized.\n",
    "    decimal_places (int, optional): The number of decimal places to scale the values. Default is 2.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: A new dataframe with the transformed and normalized values.\n",
    "    \"\"\"\n",
    "    output_df = input_df.copy()\n",
    "    for col in cols_to_transform:\n",
    "        if output_df[col].min() <= 0:\n",
    "            min_value = output_df[col][output_df[col] > 0].min()\n",
    "            output_df[col] = output_df[col].apply(lambda x: np.log(x - min_value + 1))\n",
    "        else:\n",
    "            output_df[col] = output_df[col].apply(lambda x: np.log(x))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 100))\n",
    "    output_df[cols_to_normalize] = scaler.fit_transform(output_df[cols_to_normalize]).round(decimal_places)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e0e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized = log_scaling(input_df=data, cols_to_transform=num_cols, cols_to_normalize=num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab8230",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b1fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def robust_scaling(input_df, cols_to_scale, quantile_range=(25.0, 75.0)):\n",
    "    \"\"\"\n",
    "    Apply robust scaling to the selected columns in the input dataframe and return a new dataframe with the scaled values.\n",
    "    \n",
    "    Parameters:\n",
    "    input_df (pandas.DataFrame): The input dataframe to be scaled.\n",
    "    cols_to_scale (list): A list of column names to be scaled.\n",
    "    quantile_range (tuple, optional): The quantile range used to compute the scale. Default is (25.0, 75.0).\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: A new dataframe with the scaled values.\n",
    "    \"\"\"\n",
    "    output_df = input_df.copy()\n",
    "    scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=quantile_range)\n",
    "    output_df[cols_to_scale] = scaler.fit_transform(input_df[cols_to_scale])\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce9efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply robust scaling to the selected columns\n",
    "data_normalized = robust_scaling(input_df=data, cols_to_scale=num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ed41f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422ab94d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_normalized.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f742e076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into X and y\n",
    "X = data[features]\n",
    "y = data[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a4aec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split training data into X and y\n",
    "X = data[features]\n",
    "y = data[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec09dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9691695",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09291ea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad78d32",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Convert data into LightGBM dataset format\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_val = lgb.Dataset(X_test, label=y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548b5743",
   "metadata": {},
   "source": [
    "callbacks = [early_stopping(stopping_rounds=50, eval_metric=\"aucpr\", first_metric_only=True),\n",
    "             log_evaluation(log_filename=None, period=100, show_stdv=True)]\n",
    "\n",
    "model = lgb.train(params, lgb_train, valid_sets=[lgb_val], callbacks=callbacks, num_boost_round=var_n_boost_round)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dfb3be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number of iterations\n",
    "var_n_boost_round = 200\n",
    "    \n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',  # The task is binary classification.\n",
    "        'metric': 'aucpr',  # The evaluation metric is AUCPR.\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 1000, step=100),  # The number of boosting rounds.\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'dart']),  # The type of boosting algorithm.\n",
    "        # 'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),  # The class weight balance.\n",
    "        # 'importance_type': trial.suggest_categorical('importance_type', ['split', 'gain']),  # The type of feature importance metric.\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 25, 500),  # The maximum number of leaves in one tree.\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),  # The learning rate of the boosting process.\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),  # The fraction of features to be randomly sampled for each tree.\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),  # The fraction of data to be randomly sampled for each tree.\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),  # The frequency of bagging.\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0),  # L1 regularization term on weights.\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0),  # L2 regularization term on weights.\n",
    "        # 'reg_alpha': trial.suggest_float('reg_alpha', 0, 2),\n",
    "        # 'reg_lambda': trial.suggest_float('reg_lambda', 0, 2),\n",
    "        # You need to set `feature_pre_filter=false` to dynamically change the `min_data_in_leaf`.\n",
    "        # 'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 20, 500), # The minimum number of samples required to be at a leaf node.\n",
    "        'max_depth': trial.suggest_int('max_depth', 6, 16),  # The maximum depth of a tree.\n",
    "        'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0, 1.0),  # The minimum gain to split a leaf node.\n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 1.0),  # The fraction of data to be used for each tree.\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0),  # The fraction of features to be used for each tree.\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0),  # L1 regularization term on leaf weights.\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0),  # L2 regularization term on leaf weights.\n",
    "        # 'is_unbalance': trial.suggest_categorical('is_unbalance', [True, False]),  # Whether to balance the positive and negative weights.\n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 10),  # The ratio of the sum of the weights of the negative class samples to the positive class samples.\n",
    "        'seed': 42,  # The random seed.\n",
    "        'n_jobs': -1  # Number of CPU threads to use for parallel execution, -1 means use all available CPU threads\n",
    "    }\n",
    " \n",
    "    # You need to set `feature_pre_filter=false` to dynamically change the `min_data_in_leaf`.\n",
    "        \n",
    "    # Train the LightGBM model - this does work\n",
    "    # model = lgb.train(params, lgb_train, num_boost_round=var_n_boost_round, valid_sets=[lgb_val])\n",
    "    model = lgb.train(params, lgb_train, valid_sets=[lgb_val])\n",
    "    # ----------------------------------\n",
    "    \n",
    "    # Evaluate the LightGBM model on the (internal) validation set\n",
    "    y_pred = model.predict(X_test)\n",
    "    aucpr = average_precision_score(y_test, y_pred)\n",
    "    return aucpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3889f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.logging import set_verbosity\n",
    "\n",
    "# Set the logging level to WARNING\n",
    "set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "var_n_trials = var_n_boost_round\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "# https://optuna.readthedocs.io/en/stable/reference/logging.html\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "study.optimize(objective, n_trials=var_n_trials)\n",
    "\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a73bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = study.best_trial\n",
    "best_params = best_trial.params\n",
    "\n",
    "# Set up the logger to write to a file\n",
    "logger = logging.getLogger()\n",
    "handler = logging.FileHandler(var_path_model + var_model_name_full + \"_best_parameters_apply.log\")\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Train the LightGBM model using the best hyperparameters\n",
    "# best_model = lgb.train(best_params, lgb_train, num_boost_round=var_n_boost_round, valid_sets=[lgb_val])\n",
    "best_model = lgb.train(best_params, lgb_train, valid_sets=[lgb_val])\n",
    "\n",
    "# Reverse the logging to the file on disc\n",
    "logger.removeHandler(handler)\n",
    "handler.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7a6db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the best parameters\n",
    "print(best_model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ab1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the best model on the test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# evaluate the initial values based on the (internal Test data)\n",
    "auc_pred = roc_auc_score(y_test, y_pred, average='weighted')\n",
    "print(f'Test AUC: {auc_pred:.4f}')\n",
    "\n",
    "aucpr = average_precision_score(y_test, y_pred, average='weighted', pos_label=1)\n",
    "print(f'Test AUCPR: {aucpr:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858454e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# set the path for the pickel file\n",
    "path_model = var_path_model + var_model_name_full + \"_model_stored.pkl\"\n",
    "# Save object as pickle file\n",
    "pickle.dump(best_model, open(path_model, 'wb'), pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importance\n",
    "importance = best_model.feature_importance()\n",
    "\n",
    "# Store the feature importance and column names in a Pandas DataFrame\n",
    "feature_imp = pd.DataFrame({\"Feature\": X_test.columns, \"Value\": importance})\n",
    "feature_imp = feature_imp.sort_values(by='Value', ascending=False, na_position='last')\n",
    "\n",
    "feature_imp = feature_imp.reset_index(drop=True)\n",
    "feature_imp['Feature_Rank'] = feature_imp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a44784d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_imp.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec7ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp.to_parquet(var_path_model + var_model_name_full + \"_feature_importance.parquet\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d004e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e723f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# store the variales list as dictionary in a JSON file to read back later\n",
    "\n",
    "v_variable_list = {\n",
    "    \"var_model_name\": var_model_name,\n",
    "    \"var_model_name_full\": var_model_name_full,\n",
    "    \"num_cols\": num_cols,\n",
    "    \"cat_cols\": cat_cols,\n",
    "    \"rest_cols\": rest_cols,\n",
    "    \"label\": label,\n",
    "    \"features\": features,\n",
    "    \"excluded_features\": excluded_features,\n",
    "    \"Test_AUC\": f'{auc_pred:.5f}',\n",
    "    \"Test_AUCPR\": f'{aucpr:.5f}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v_variable_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbce94d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(v_variable_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51902450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write the dictionary to a JSON file\n",
    "with open(var_path_model + var_model_name_full + \"_variable_list.json\", \"w\") as f:\n",
    "    json.dump(v_variable_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0206df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the best parameters\n",
    "best_parameters = best_model.params\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6823b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(var_path_model + var_model_name_full + \"_model_parameters.txt\", \"w\") as file:\n",
    "    print(best_parameters, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a0d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_parameters = pd.read_csv(var_path_model + var_model_name_full + \"_model_parameters.txt\", sep = \"@\",header = None, names=[\"lgbm_parameters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1550e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_parameters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b08c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for Image\n",
    "var_path_opt_history_png = var_path_model + var_model_name_full + \"_opt_history.png\"\n",
    "\n",
    "# Plot the optimization history and save to a file\n",
    "fig = plot_optimization_history(study)\n",
    "fig.write_image(var_path_opt_history_png)    \n",
    "\n",
    "# Plot the hyperparameter importances - this pictures might get large so maybe look at them in the PNG file\n",
    "# plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02b99e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for Image\n",
    "var_path_param_importances_png = var_path_model + var_model_name_full + \"_param_importances.png\"\n",
    "\n",
    "# Plot the hyperparameter importances and save to a file\n",
    "fig_para = plot_param_importances(study)\n",
    "fig_para.write_image(var_path_param_importances_png)\n",
    "\n",
    "# Plot the hyperparameter importances - this pictures might get large so maybe look at them in the PNG file\n",
    "# plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1840771a",
   "metadata": {},
   "source": [
    "## Apply the LightGBM model with all the settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f52ff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# set the path for the pickel file\n",
    "path_apply_model = var_path_model + var_model_name_full + \"_model_stored.pkl\"\n",
    "\n",
    "clf_apply = pickle.load(open(path_apply_model, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fb22dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file back into a Python dictionary\n",
    "with open(var_path_model + var_model_name_full + \"_variable_list.json\", \"r\") as f:\n",
    "    loaded_dict = json.load(f)\n",
    "\n",
    "# fill the list of categorical columns\n",
    "new_cat_cols = loaded_dict['cat_cols']\n",
    "new_features = loaded_dict['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3941a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636830e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test_apply = data_test[new_features].copy()\n",
    "df_test_apply[new_cat_cols] = df_test_apply[new_cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c00066",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the predicted probabilities for each class\n",
    "probabilities = clf_apply.predict(df_test_apply)\n",
    "# prediction = clf_apply.predict(df_test_apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaca9659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probabilities_df = pd.DataFrame(probabilities, columns = ['P1'])\n",
    "# prediction_df = pd.DataFrame(prediction, columns = ['Target_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319944ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab9064a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Join the original target column with the predicted probabilities\n",
    "result = pd.concat([data_test, probabilities_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd897cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a5938d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result.to_parquet(var_path_data + var_model_name_full + \"_scored_test_data.parquet\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d12475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate the best model on the test data\n",
    "auc_pred = roc_auc_score(result['Target'], result['P1'], average='weighted')\n",
    "print(f'Test AUC: {auc_pred:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f73a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import average_precision_score\n",
    "aucpr = average_precision_score(result['Target'], result['P1'], average='weighted', pos_label='1')\n",
    "print(f'Test AUCPR: {aucpr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307a5f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_true = result[\"Target\"].astype(int).values\n",
    "y_score = result[\"P1\"].values\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n",
    "auc_pr = np.trapz(precision, recall)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.gcf().set_size_inches(10.24, 7.68)\n",
    "plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall curve: AUCPR={0:0.4f}'.format(auc_pr))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb24265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d03310f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
